{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfbcb86d",
   "metadata": {},
   "source": [
    "# Run Hugging Face flan-t5-xxl\n",
    "`  sampling on Inf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c69d635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/aws-neuron/transformers-neuronx.git transformers -U\n",
    "# !pip install accelerate\n",
    "# !pip install SentencePiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a032b339",
   "metadata": {},
   "source": [
    "## Download and construct the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a93feb",
   "metadata": {},
   "source": [
    "We download and construct the `facebook/opt-13b` model using the Hugging Face `from_pretrained` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6db7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_neuronx\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66f9b8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d95ae533a34130abce99365eab70a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac3aca3bad74674a7e469a00d984a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbacd2f652d847ec9fc147a5a94a1b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34538508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8876a3968304a7da23754cafe707fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00004-of-00005.bin:   0%|          | 0.00/10.0G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b02077a39340a3852cf3fd48751bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00005-of-00005.bin:   0%|          | 0.00/6.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187076ab7fc940f49ec2450eb1f725ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac859763fcb549dbaf8d50408398d2d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xxl\", device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30c6840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8b00e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Wie alt sind Sie?</s>\n"
     ]
    }
   ],
   "source": [
    "input_text = \"translate English to German: How old are you?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2efd0402",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to('xla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5b4b84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21T08:37:35Z WARNING 412501 [py.warnings]: /opt/aws_neuron_venv_pytorch/bin/neuronx-cc:8: RuntimeWarning: overflow encountered in int_scalars\n",
      "  sys.exit(main())\n",
      "\n",
      "2023-05-21T08:37:35Z WARNING 412501 [LayoutBottleneck]: Connected component _subtract.1 has no matmult/reduce/batchnorm. Guessing layout. Considering putting on CPU.\n"
     ]
    }
   ],
   "source": [
    "model_neuron = torch_neuronx.trace(model.generate, input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5566815",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model_flan-t5-xxl.pt'\n",
    "torch.jit.save(model_neuron, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9fd06dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> Wie alt sind Sie?</s>\n"
     ]
    }
   ],
   "source": [
    "model_neuron_load = torch.jit.load(filename) \n",
    "neuron_outputs=model_neuron_load(input_ids)\n",
    "print(tokenizer.decode(neuron_outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4e4c1e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.14B\n"
     ]
    }
   ],
   "source": [
    "def parameters_calc(model, flag):\n",
    "    parameter = sum(p.numel() for p in model.parameters())\n",
    "    multipliers = {'K':10**3, 'M':10**6, 'B':10**9}\n",
    "    \n",
    "    mult = int(multipliers[flag]) # look up suffix to get multiplier\n",
    "     # convert number to float, multiply by multiplier, then make int\n",
    "    return str(round(float(parameter) / mult, 2)) + flag\n",
    "\n",
    "\n",
    "print(parameters_calc(model, 'B'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8495060b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuron_venv_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
